{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "2023-03-10 22:49:14.551334: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-10 22:49:14.551356: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#Import lib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from my_useful_functions import calculate_performance_statistical_parity,calculate_performance_equalized_odds,calculate_performance_equal_opportunity,calculate_performance_predictive_parity,calculate_performance_predictive_equality,calculate_performance_treatment_equality\n",
    "from sklearn import preprocessing\n",
    "from exponentiated_gradient_reduction import ExponentiatedGradientReduction\n",
    "#Estimator\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from compute_abroca import *\n",
    "from calibrated_eq_odds_postprocessing import CalibratedEqOddsPostprocessing\n",
    "from aif360.datasets.binary_label_dataset import BinaryLabelDataset\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics \n",
    "from scipy import interpolate\n",
    "from scipy import integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://archive.ics.uci.edu/ml/datasets/credit+approval\n",
    "#http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html\n",
    "#https://www.kaggle.com/code/chandanabhatt/prediction-of-credit-approval\n",
    "# Credit approval dataset\n",
    "# $ Male          : num  1 1 0 0 0 0 1 0 0 0 ...\n",
    "# $ Age           : chr  \"58.67\" \"24.50\" \"27.83\" \"20.17\" ...\n",
    "# $ Debt          : num  4.46 0.5 1.54 5.62 4 ...\n",
    "# $ Married       : chr  \"u\" \"u\" \"u\" \"u\" ...\n",
    "# $ BankCustomer  : chr  \"g\" \"g\" \"g\" \"g\" ...\n",
    "# $ EducationLevel: chr  \"q\" \"q\" \"w\" \"w\" ...\n",
    "# $ Ethnicity     : chr  \"h\" \"h\" \"v\" \"v\" ...\n",
    "# $ YearsEmployed : num  3.04 1.5 3.75 1.71 2.5 ...\n",
    "# $ PriorDefault  : num  1 1 1 1 1 1 1 1 1 0 ...\n",
    "# $ Employed      : num  1 0 1 0 0 0 0 0 0 0 ...\n",
    "# $ CreditScore   : num  6 0 5 0 0 0 0 0 0 0 ...\n",
    "# $ DriversLicense: chr  \"f\" \"f\" \"t\" \"f\" ...\n",
    "# $ Citizen       : chr  \"g\" \"g\" \"g\" \"s\" ...\n",
    "# $ ZipCode       : chr  \"00043\" \"00280\" \"00100\" \"00120\" ...\n",
    "# $ Income        : num  560 824 3 0 0 ...\n",
    "# $ Approved      : chr  \"+\" \"+\" \"+\" \"+\" ...\n",
    "\n",
    "def load_credit_approval():\n",
    "    df = pd.read_csv('data/credit-approval.data',sep=\",\")\n",
    "    protected_attribute = 'Male'\n",
    "    majority_group_name = \"Female\"\n",
    "    minority_group_name = \"Male\"\n",
    "    class_label = 'Approved'\n",
    "    filename = \"EOP_DT.credit_approval.abroca.png\"\n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    #Remove missing value\n",
    "    df = df[df['Male'] != '?']   \n",
    "    #Label sex\n",
    "    df['Male']=[\"Female\" if v == \"a\" else \"Male\" for v in df['Male']]\n",
    "    #Label class\n",
    "    df['Approved']=[1 if v == \"+\" else 0 for v in df['Approved']]\n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit card client\n",
    "#Gender (1 = male; 2 = female)\n",
    "def load_credit_card():\n",
    "    df = pd.read_csv('data/credit-card-clients.csv')    \n",
    "    protected_attribute = 'SEX'\n",
    "    majority_group_name = \"Male\"\n",
    "    minority_group_name = \"Female\"\n",
    "    class_label = 'default payment'\n",
    "    filename = \"EOP_DT.credit_card.abroca.png\"   \n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    \n",
    "    #Label sex\n",
    "    df['SEX']=[\"Female\" if v == 2 else \"Male\" for v in df['SEX']]\n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    \n",
    "    #label encode\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#German credit\n",
    "def load_german_credit():\n",
    "    df = pd.read_csv('data/german_data_credit.csv')    \n",
    "    protected_attribute = 'sex'\n",
    "    majority_group_name = \"male\"\n",
    "    minority_group_name = \"female\"\n",
    "    class_label = 'class-label'\n",
    "    filename = \"EOP_DT.german_credit.abroca.png\"    \n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    #label encode\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_PAKDD2010():\n",
    "    df = pd.read_csv('data/PAKDD.csv')    \n",
    "    protected_attribute = 'SEX'\n",
    "    majority_group_name = \"Male\"\n",
    "    minority_group_name = \"Female\"\n",
    "    class_label = 'TARGET_LABEL_BAD'\n",
    "    filename = \"EOP_DT.PAKDD.abroca.png\"    \n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    \n",
    "    #Remove ID\n",
    "    df=df.drop(columns=['ID_CLIENT'])\n",
    "    df =df.dropna()\n",
    "    df=df.drop(columns = ['RESIDENCIAL_PHONE_AREA_CODE','RESIDENCIAL_ZIP_3','PROFESSIONAL_ZIP_3'])\n",
    "    #Label sex\n",
    "    df['SEX']=[\"Female\" if v == \"F\" else \"Male\" for v in df['SEX']]\n",
    "    \n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    \n",
    "    #label encode\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit scoring data\n",
    "#https://www.kaggle.com/code/islombekdavronov/credit-scoring\n",
    "#FinTech companies in Central Asia.\n",
    "def load_credit_scoring():\n",
    "    df = pd.read_csv('data/credit_scoring.csv')    \n",
    "    protected_attribute = 'Sex'\n",
    "    majority_group_name = \"Male\"\n",
    "    minority_group_name = \"Female\"\n",
    "    class_label = 'label'\n",
    "    filename = \"EOP_DT.credit_scoring.abroca.png\"    \n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    \n",
    "    df = df.replace({'-':0})\n",
    "    df['Score_point']=df['Score_point'].astype(float)\n",
    "    \n",
    "       \n",
    "    #Label sex\n",
    "    df['Sex']=[\"Female\" if v == 2 else \"Male\" for v in df['Sex']]\n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    \n",
    "    #label encode\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,1:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name):    \n",
    "      \n",
    "    #Run DT model, thay doi ca proba ca predict lieu co dung ?\n",
    "    clf =  NB = GaussianNB()\n",
    "    Reduction = ExponentiatedGradientReduction(prot_attr=protected_attribute,estimator=clf, constraints = \"EqualizedOdds\")\n",
    "    Reduction.fit(X_train,y_train)\n",
    "    y_test_predicts = Reduction.predict(X_test)\n",
    "    y_train_predicts = Reduction.predict(X_train)\n",
    "\n",
    "    X_train_predicts = X_train.copy()\n",
    "    X_test_predicts = X_test.copy()\n",
    "\n",
    "    X_train_predicts[y_train.name] = y_train_predicts\n",
    "    X_test_predicts[y_train.name] = y_test_predicts\n",
    "\n",
    "    privileged_groups = [{protected_attribute: 1.0}]\n",
    "    unprivileged_groups = [{protected_attribute: 0.0}]\n",
    "    cep = CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=42)\n",
    "    #Create true dataset and pred dataset\n",
    "    dataset_train_true = BinaryLabelDataset(df=pd.concat([X_train, y_train.to_frame()], axis=1), label_names=[y_train.name], protected_attribute_names=[protected_attribute])\n",
    "    dataset_train_predicts = BinaryLabelDataset(df=X_train_predicts, label_names=[y_train.name], protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    # dataset_test_true = BinaryLabelDataset(df=pd.concat([X_test, y_test.to_frame()], axis=1), label_names=[y_test.name], protected_attribute_names=[protected_attribute])\n",
    "    dataset_test_predicts = BinaryLabelDataset(df=X_test_predicts, label_names=[y_test.name], protected_attribute_names=[protected_attribute])\n",
    "    # dataset_pred_proba = BinaryLabelDataset(df=X_pred_proba, label_names=[y_test.name], protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    cep.fit_predict(dataset_true=dataset_train_true, dataset_pred=dataset_train_predicts)\n",
    "    dataset_predicts_transf = cep.predict(dataset_test_predicts)\n",
    "    # dataset_pred_proba_transf = eop.fit_predict(dataset_true=dataset_true, dataset_pred=dataset_pred_proba)\n",
    "\n",
    "    data_predicts = dataset_predicts_transf.convert_to_dataframe()[0]\n",
    "    # data_pred_proba = dataset_pred_proba_transf.convert_to_dataframe()[0]\n",
    "\n",
    "    y_transf_predicts = data_predicts[y_test.name].astype(int)\n",
    "    # y_transf_pred_proba = data_pred_proba[y_test.name].astype(int)\n",
    "        \n",
    "    #Print measures, use new pred instead of old pred\n",
    "        \n",
    "    print(\"Statistical parity:\")\n",
    "    print(calculate_performance_statistical_parity(X_test.values, y_test.values, y_transf_predicts.values, sa_index, p_Group))\n",
    "         \n",
    "    print(\"Equal opportunity\")\n",
    "    print(calculate_performance_equal_opportunity(X_test.values, y_test.values, y_transf_predicts.values,  sa_index, p_Group))\n",
    "        \n",
    "    # print(\"Equalized odds\")\n",
    "    # # print(calculate_performance_equalized_odds(X_test.values, y_test.values, y_transf_predicts.values, y_transf_pred_proba.values, sa_index, p_Group))\n",
    "    # print(calculate_performance_equalized_odds(X_test.values, y_test.values, y_transf_predicts.values, y_transf_predicts.values, sa_index, p_Group))\n",
    "         \n",
    "    print(\"Predictive parity\")\n",
    "    print(calculate_performance_predictive_parity(X_test.values, y_test.values, y_transf_predicts.values,  sa_index, p_Group))\n",
    "        \n",
    "    print(\"Predictive equality\")\n",
    "    print(calculate_performance_predictive_equality(X_test.values, y_test.values, y_transf_predicts.values,  sa_index, p_Group))\n",
    "        \n",
    "    print(\"Treatment equality\")\n",
    "    print(calculate_performance_treatment_equality(X_test.values, y_test.values, y_transf_predicts.values,  sa_index, p_Group))\n",
    "        \n",
    "    # \n",
    "    \n",
    "    #make predictions\n",
    "    # X_test['pred_proba'] = y_transf_predicts.values\n",
    "    # X_test['true_label'] = y_test\n",
    "    # df_test = X_test\n",
    "    \n",
    "    # #Compute Abroca\n",
    "    # slice = compute_abroca(df_test, pred_col = 'pred_proba' , label_col = 'true_label', protected_attr_col = protected_attribute,\n",
    "    #                        majority_protected_attr_val = 1, n_grid = 10000,\n",
    "    #                        plot_slices = True, majority_group_name=majority_group_name ,minority_group_name=minority_group_name,file_name = filename)\n",
    "    # print(\"ABROCA:\",slice)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function\n",
    "def run_eval(dataset):\n",
    "    if dataset == 'credit-approval':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_credit_approval()\n",
    "        run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                        \n",
    "    if dataset == 'credit-card':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_credit_card()\n",
    "        run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                        \n",
    "    if dataset == 'german-credit':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_german_credit()\n",
    "        run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                            \n",
    "    if dataset == 'PAKDD':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_PAKDD2010()\n",
    "        run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                                                \n",
    "    if dataset == 'credit-scoring':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_credit_scoring()\n",
    "        run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                                                        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 690\n",
      "Number of attribute: 16\n",
      "Length (cleaned): 678\n",
      "Class imbalance: \n",
      " 0    374\n",
      "1    304\n",
      "Name: Approved, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.7783625730994153, 'accuracy': 0.7941176470588235, 'f1-score': 0.7341772151898734, 'fairness': 0.01505257332595461}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.7783625730994153, 'accuracy': 0.7941176470588235, 'f1-score': 0.7341772151898734, 'fairness': 0.013221153846153855, 'TPR_protected': 0.6538461538461539, 'TPR_non_protected': 0.640625, 'TNR_protected': 0.8974358974358975, 'TNR_non_protected': 0.92}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.7783625730994153, 'accuracy': 0.7941176470588235, 'f1-score': 0.7341772151898734, 'fairness': 0.0628166160081054, 'TPR_protected': 0.6538461538461539, 'TPR_non_protected': 0.640625, 'TNR_protected': 0.8974358974358975, 'TNR_non_protected': 0.92}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.7783625730994153, 'accuracy': 0.7941176470588235, 'f1-score': 0.7341772151898734, 'fairness': 0.02256410256410256, 'TPR_protected': 0.6538461538461539, 'TPR_non_protected': 0.640625, 'TNR_protected': 0.8974358974358975, 'TNR_non_protected': 0.92}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.7783625730994153, 'accuracy': 0.7941176470588235, 'f1-score': 0.7341772151898734, 'fairness': -1.5833333333333335, 'TPR_protected': 0.6538461538461539, 'TPR_non_protected': 0.640625, 'TNR_protected': 0.8974358974358975, 'TNR_non_protected': 0.92}\n"
     ]
    }
   ],
   "source": [
    "run_eval('credit-approval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 30000\n",
      "Number of attribute: 24\n",
      "Length (cleaned): 30000\n",
      "Class imbalance: \n",
      " 0    23364\n",
      "1     6636\n",
      "Name: default payment, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.49866941094619666, 'accuracy': 0.5284444444444445, 'f1-score': 0.2917222963951936, 'fairness': 0.02350368852155771}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.49866941094619666, 'accuracy': 0.5284444444444445, 'f1-score': 0.2917222963951936, 'fairness': 0.02121686523204286, 'TPR_protected': 0.4367713004484305, 'TPR_non_protected': 0.45798816568047335, 'TNR_protected': 0.5609641937748654, 'TNR_non_protected': 0.5366823274304301}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.49866941094619666, 'accuracy': 0.5284444444444445, 'f1-score': 0.2917222963951936, 'fairness': 0.025781426105018795, 'TPR_protected': 0.4367713004484305, 'TPR_non_protected': 0.45798816568047335, 'TNR_protected': 0.5609641937748654, 'TNR_non_protected': 0.5366823274304301}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.49866941094619666, 'accuracy': 0.5284444444444445, 'f1-score': 0.2917222963951936, 'fairness': 0.024281866344435354, 'TPR_protected': 0.4367713004484305, 'TPR_non_protected': 0.45798816568047335, 'TNR_protected': 0.5609641937748654, 'TNR_non_protected': 0.5366823274304301}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.49866941094619666, 'accuracy': 0.5284444444444445, 'f1-score': 0.2917222963951936, 'fairness': -0.022499492730242265, 'TPR_protected': 0.4367713004484305, 'TPR_non_protected': 0.45798816568047335, 'TNR_protected': 0.5609641937748654, 'TNR_non_protected': 0.5366823274304301}\n"
     ]
    }
   ],
   "source": [
    "run_eval('credit-card')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 8755\n",
      "Number of attribute: 18\n",
      "Length (cleaned): 8755\n",
      "Class imbalance: \n",
      " 1    8059\n",
      "0     696\n",
      "Name: label, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.8996379807044443, 'accuracy': 0.9645984012181196, 'f1-score': 0.9805642633228839, 'fairness': 0.06071523836109294}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.8996379807044443, 'accuracy': 0.9645984012181196, 'f1-score': 0.9805642633228839, 'fairness': 0.020808219349990442, 'TPR_protected': 0.9704102219233356, 'TPR_non_protected': 0.991218441273326, 'TNR_protected': 0.8834355828220859, 'TNR_non_protected': 0.6666666666666666}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.8996379807044443, 'accuracy': 0.9645984012181196, 'f1-score': 0.9805642633228839, 'fairness': 0.010787887750952074, 'TPR_protected': 0.9704102219233356, 'TPR_non_protected': 0.991218441273326, 'TNR_protected': 0.8834355828220859, 'TNR_non_protected': 0.6666666666666666}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.8996379807044443, 'accuracy': 0.9645984012181196, 'f1-score': 0.9805642633228839, 'fairness': 0.2167689161554192, 'TPR_protected': 0.9704102219233356, 'TPR_non_protected': 0.991218441273326, 'TNR_protected': 0.8834355828220859, 'TNR_non_protected': 0.6666666666666666}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.8996379807044443, 'accuracy': 0.9645984012181196, 'f1-score': 0.9805642633228839, 'fairness': 1.9521531100478469, 'TPR_protected': 0.9704102219233356, 'TPR_non_protected': 0.991218441273326, 'TNR_protected': 0.8834355828220859, 'TNR_non_protected': 0.6666666666666666}\n"
     ]
    }
   ],
   "source": [
    "run_eval('credit-scoring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 1000\n",
      "Number of attribute: 22\n",
      "Length (cleaned): 1000\n",
      "Class imbalance: \n",
      " 1    700\n",
      "0    300\n",
      "Name: class-label, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.6102581628897419, 'accuracy': 0.7033333333333334, 'f1-score': 0.7990970654627538, 'fairness': -0.054030874785591765}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.6102581628897419, 'accuracy': 0.7033333333333334, 'f1-score': 0.7990970654627538, 'fairness': 0.0716384180790961, 'TPR_protected': 0.8983050847457628, 'TPR_non_protected': 0.8266666666666667, 'TNR_protected': 0.3448275862068966, 'TNR_non_protected': 0.3870967741935484}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.6102581628897419, 'accuracy': 0.7033333333333334, 'f1-score': 0.7990970654627538, 'fairness': 0.029320987654320896, 'TPR_protected': 0.8983050847457628, 'TPR_non_protected': 0.8266666666666667, 'TNR_protected': 0.3448275862068966, 'TNR_non_protected': 0.3870967741935484}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.6102581628897419, 'accuracy': 0.7033333333333334, 'f1-score': 0.7990970654627538, 'fairness': 0.0422691879866518, 'TPR_protected': 0.8983050847457628, 'TPR_non_protected': 0.8266666666666667, 'TNR_protected': 0.3448275862068966, 'TNR_non_protected': 0.3870967741935484}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.6102581628897419, 'accuracy': 0.7033333333333334, 'f1-score': 0.7990970654627538, 'fairness': -0.368421052631579, 'TPR_protected': 0.8983050847457628, 'TPR_non_protected': 0.8266666666666667, 'TNR_protected': 0.3448275862068966, 'TNR_non_protected': 0.3870967741935484}\n"
     ]
    }
   ],
   "source": [
    "run_eval('german-credit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 50000\n",
      "Number of attribute: 47\n",
      "Length (cleaned): 38896\n",
      "Class imbalance: \n",
      " 0    28747\n",
      "1    10149\n",
      "Name: TARGET_LABEL_BAD, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.5088757875339294, 'accuracy': 0.7273116805210387, 'f1-score': 0.07981492192018508, 'fairness': 0.003029481237291555}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.5088757875339294, 'accuracy': 0.7273116805210387, 'f1-score': 0.07981492192018508, 'fairness': 0.007960308710033073, 'TPR_protected': 0.047960308710033074, 'TPR_non_protected': 0.04, 'TNR_protected': 0.9755363191569439, 'TNR_non_protected': 0.9690753214941825}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.5088757875339294, 'accuracy': 0.7273116805210387, 'f1-score': 0.07981492192018508, 'fairness': 0.06539534319670143, 'TPR_protected': 0.047960308710033074, 'TPR_non_protected': 0.04, 'TNR_protected': 0.9755363191569439, 'TNR_non_protected': 0.9690753214941825}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.5088757875339294, 'accuracy': 0.7273116805210387, 'f1-score': 0.07981492192018508, 'fairness': 0.006460997662761436, 'TPR_protected': 0.047960308710033074, 'TPR_non_protected': 0.04, 'TNR_protected': 0.9755363191569439, 'TNR_non_protected': 0.9690753214941825}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.5088757875339294, 'accuracy': 0.7273116805210387, 'f1-score': 0.07981492192018508, 'fairness': 1.1658035034272665, 'TPR_protected': 0.047960308710033074, 'TPR_non_protected': 0.04, 'TNR_protected': 0.9755363191569439, 'TNR_non_protected': 0.9690753214941825}\n"
     ]
    }
   ],
   "source": [
    "run_eval('PAKDD')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "07f77a1088ec27c511ada81280526a5a9813c372362ef5dc18ab18682e528864"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
