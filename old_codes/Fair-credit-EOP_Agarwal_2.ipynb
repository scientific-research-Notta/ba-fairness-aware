{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import lib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from my_useful_functions import calculate_performance_statistical_parity,calculate_performance_equalized_odds,calculate_performance_equal_opportunity,calculate_performance_predictive_parity,calculate_performance_predictive_equality,calculate_performance_treatment_equality\n",
    "from sklearn import preprocessing\n",
    "from exponentiated_gradient_reduction import ExponentiatedGradientReduction\n",
    "#Estimator\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from eq_odds_postprocessing import EqOddsPostprocessing\n",
    "from aif360.datasets.binary_label_dataset import BinaryLabelDataset\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics \n",
    "from scipy import interpolate\n",
    "from scipy import integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://archive.ics.uci.edu/ml/datasets/credit+approval\n",
    "#http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html\n",
    "#https://www.kaggle.com/code/chandanabhatt/prediction-of-credit-approval\n",
    "# Credit approval dataset\n",
    "# $ Male          : num  1 1 0 0 0 0 1 0 0 0 ...\n",
    "# $ Age           : chr  \"58.67\" \"24.50\" \"27.83\" \"20.17\" ...\n",
    "# $ Debt          : num  4.46 0.5 1.54 5.62 4 ...\n",
    "# $ Married       : chr  \"u\" \"u\" \"u\" \"u\" ...\n",
    "# $ BankCustomer  : chr  \"g\" \"g\" \"g\" \"g\" ...\n",
    "# $ EducationLevel: chr  \"q\" \"q\" \"w\" \"w\" ...\n",
    "# $ Ethnicity     : chr  \"h\" \"h\" \"v\" \"v\" ...\n",
    "# $ YearsEmployed : num  3.04 1.5 3.75 1.71 2.5 ...\n",
    "# $ PriorDefault  : num  1 1 1 1 1 1 1 1 1 0 ...\n",
    "# $ Employed      : num  1 0 1 0 0 0 0 0 0 0 ...\n",
    "# $ CreditScore   : num  6 0 5 0 0 0 0 0 0 0 ...\n",
    "# $ DriversLicense: chr  \"f\" \"f\" \"t\" \"f\" ...\n",
    "# $ Citizen       : chr  \"g\" \"g\" \"g\" \"s\" ...\n",
    "# $ ZipCode       : chr  \"00043\" \"00280\" \"00100\" \"00120\" ...\n",
    "# $ Income        : num  560 824 3 0 0 ...\n",
    "# $ Approved      : chr  \"+\" \"+\" \"+\" \"+\" ...\n",
    "\n",
    "def load_credit_approval():\n",
    "    df = pd.read_csv('data/credit-approval.data',sep=\",\")\n",
    "    protected_attribute = 'Male'\n",
    "    majority_group_name = \"Female\"\n",
    "    minority_group_name = \"Male\"\n",
    "    class_label = 'Approved'\n",
    "    filename = \"EOP_DT.credit_approval.abroca.png\"\n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    #Remove missing value\n",
    "    df = df[df['Male'] != '?']   \n",
    "    #Label sex\n",
    "    df['Male']=[\"Female\" if v == \"a\" else \"Male\" for v in df['Male']]\n",
    "    #Label class\n",
    "    df['Approved']=[1 if v == \"+\" else 0 for v in df['Approved']]\n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit card client\n",
    "#Gender (1 = male; 2 = female)\n",
    "def load_credit_card():\n",
    "    df = pd.read_csv('data/credit-card-clients.csv')    \n",
    "    protected_attribute = 'SEX'\n",
    "    majority_group_name = \"Male\"\n",
    "    minority_group_name = \"Female\"\n",
    "    class_label = 'default payment'\n",
    "    filename = \"EOP_DT.credit_card.abroca.png\"   \n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    \n",
    "    #Label sex\n",
    "    df['SEX']=[\"Female\" if v == 2 else \"Male\" for v in df['SEX']]\n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    \n",
    "    #label encode\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#German credit\n",
    "def load_german_credit():\n",
    "    df = pd.read_csv('data/german_data_credit.csv')    \n",
    "    protected_attribute = 'sex'\n",
    "    majority_group_name = \"male\"\n",
    "    minority_group_name = \"female\"\n",
    "    class_label = 'class-label'\n",
    "    filename = \"EOP_DT.german_credit.abroca.png\"    \n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    #label encode\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_PAKDD2010():\n",
    "    df = pd.read_csv('data/PAKDD.csv')    \n",
    "    protected_attribute = 'SEX'\n",
    "    majority_group_name = \"Male\"\n",
    "    minority_group_name = \"Female\"\n",
    "    class_label = 'TARGET_LABEL_BAD'\n",
    "    filename = \"EOP_DT.PAKDD.abroca.png\"    \n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    \n",
    "    #Remove ID\n",
    "    df=df.drop(columns=['ID_CLIENT'])\n",
    "    df =df.dropna()\n",
    "    df=df.drop(columns = ['RESIDENCIAL_PHONE_AREA_CODE','RESIDENCIAL_ZIP_3','PROFESSIONAL_ZIP_3'])\n",
    "    #Label sex\n",
    "    df['SEX']=[\"Female\" if v == \"F\" else \"Male\" for v in df['SEX']]\n",
    "    \n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    \n",
    "    #label encode\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit scoring data\n",
    "#https://www.kaggle.com/code/islombekdavronov/credit-scoring\n",
    "#FinTech companies in Central Asia.\n",
    "def load_credit_scoring():\n",
    "    df = pd.read_csv('data/credit_scoring.csv')    \n",
    "    protected_attribute = 'Sex'\n",
    "    majority_group_name = \"Male\"\n",
    "    minority_group_name = \"Female\"\n",
    "    class_label = 'label'\n",
    "    filename = \"EOP_DT.credit_scoring.abroca.png\"    \n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    \n",
    "    df = df.replace({'-':0})\n",
    "    df['Score_point']=df['Score_point'].astype(float)\n",
    "    \n",
    "       \n",
    "    #Label sex\n",
    "    df['Sex']=[\"Female\" if v == 2 else \"Male\" for v in df['Sex']]\n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    \n",
    "    #label encode\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,1:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name):    \n",
    "      \n",
    "    #Run DT model, thay doi ca proba ca predict lieu co dung ?\n",
    "    clf =  NB = GaussianNB()\n",
    "    Reduction = ExponentiatedGradientReduction(prot_attr=protected_attribute,estimator=clf, constraints = \"EqualizedOdds\")\n",
    "    Reduction.fit(X_train,y_train)\n",
    "    y_test_predicts = Reduction.predict(X_test)\n",
    "    y_train_predicts = Reduction.predict(X_train)\n",
    "\n",
    "    X_train_predicts = X_train.copy()\n",
    "    X_test_predicts = X_test.copy()\n",
    "\n",
    "    X_train_predicts[y_train.name] = y_train_predicts\n",
    "    X_test_predicts[y_train.name] = y_test_predicts\n",
    "\n",
    "    privileged_groups = [{protected_attribute: 1.0}]\n",
    "    unprivileged_groups = [{protected_attribute: 0.0}]\n",
    "    eop = EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=42)\n",
    "    #Create true dataset and pred dataset\n",
    "    dataset_train_true = BinaryLabelDataset(df=pd.concat([X_train, y_train.to_frame()], axis=1), label_names=[y_train.name], protected_attribute_names=[protected_attribute])\n",
    "    dataset_train_predicts = BinaryLabelDataset(df=X_train_predicts, label_names=[y_train.name], protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    # dataset_test_true = BinaryLabelDataset(df=pd.concat([X_test, y_test.to_frame()], axis=1), label_names=[y_test.name], protected_attribute_names=[protected_attribute])\n",
    "    dataset_test_predicts = BinaryLabelDataset(df=X_test_predicts, label_names=[y_test.name], protected_attribute_names=[protected_attribute])\n",
    "    # dataset_pred_proba = BinaryLabelDataset(df=X_pred_proba, label_names=[y_test.name], protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    eop.fit_predict(dataset_true=dataset_train_true, dataset_pred=dataset_train_predicts)\n",
    "    dataset_predicts_transf = eop.predict(dataset_test_predicts)\n",
    "    # dataset_pred_proba_transf = eop.fit_predict(dataset_true=dataset_true, dataset_pred=dataset_pred_proba)\n",
    "\n",
    "    data_predicts = dataset_predicts_transf.convert_to_dataframe()[0]\n",
    "    # data_pred_proba = dataset_pred_proba_transf.convert_to_dataframe()[0]\n",
    "\n",
    "    y_transf_predicts = data_predicts[y_test.name].astype(int)\n",
    "    # y_transf_pred_proba = data_pred_proba[y_test.name].astype(int)\n",
    "        \n",
    "    #Print measures, use new pred instead of old pred\n",
    "        \n",
    "    print(\"Statistical parity:\")\n",
    "    print(calculate_performance_statistical_parity(X_test.values, y_test.values, y_transf_predicts.values, sa_index, p_Group))\n",
    "         \n",
    "    print(\"Equal opportunity\")\n",
    "    print(calculate_performance_equal_opportunity(X_test.values, y_test.values, y_transf_predicts.values,  sa_index, p_Group))\n",
    "        \n",
    "    # print(\"Equalized odds\")\n",
    "    # # print(calculate_performance_equalized_odds(X_test.values, y_test.values, y_transf_predicts.values, y_transf_pred_proba.values, sa_index, p_Group))\n",
    "    # print(calculate_performance_equalized_odds(X_test.values, y_test.values, y_transf_predicts.values, y_transf_predicts.values, sa_index, p_Group))\n",
    "         \n",
    "    print(\"Predictive parity\")\n",
    "    print(calculate_performance_predictive_parity(X_test.values, y_test.values, y_transf_predicts.values,  sa_index, p_Group))\n",
    "        \n",
    "    print(\"Predictive equality\")\n",
    "    print(calculate_performance_predictive_equality(X_test.values, y_test.values, y_transf_predicts.values,  sa_index, p_Group))\n",
    "        \n",
    "    print(\"Treatment equality\")\n",
    "    print(calculate_performance_treatment_equality(X_test.values, y_test.values, y_transf_predicts.values,  sa_index, p_Group))\n",
    "        \n",
    "    # \n",
    "    \n",
    "    #make predictions\n",
    "    # X_test['pred_proba'] = y_transf_predicts.values\n",
    "    # X_test['true_label'] = y_test\n",
    "    # df_test = X_test\n",
    "    \n",
    "    # #Compute Abroca\n",
    "    # slice = compute_abroca(df_test, pred_col = 'pred_proba' , label_col = 'true_label', protected_attr_col = protected_attribute,\n",
    "    #                        majority_protected_attr_val = 1, n_grid = 10000,\n",
    "    #                        plot_slices = True, majority_group_name=majority_group_name ,minority_group_name=minority_group_name,file_name = filename)\n",
    "    # print(\"ABROCA:\",slice)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function\n",
    "def run_eval(dataset):\n",
    "    if dataset == 'credit-approval':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_credit_approval()\n",
    "        run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                        \n",
    "    if dataset == 'credit-card':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_credit_card()\n",
    "        run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                        \n",
    "    if dataset == 'german-credit':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_german_credit()\n",
    "        run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                            \n",
    "    if dataset == 'PAKDD':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_PAKDD2010()\n",
    "        run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                                                \n",
    "    if dataset == 'credit-scoring':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_credit_scoring()\n",
    "        run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                                                        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 690\n",
      "Number of attribute: 16\n",
      "Length (cleaned): 678\n",
      "Class imbalance: \n",
      " 0    374\n",
      "1    304\n",
      "Name: Approved, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.7783625730994153, 'accuracy': 0.7941176470588235, 'f1-score': 0.7341772151898734, 'fairness': 0.03763143331488655}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.7783625730994153, 'accuracy': 0.7941176470588235, 'f1-score': 0.7341772151898734, 'fairness': 0.09495192307692313, 'TPR_protected': 0.5769230769230769, 'TPR_non_protected': 0.671875, 'TNR_protected': 0.8717948717948718, 'TNR_non_protected': 0.9333333333333333}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.7783625730994153, 'accuracy': 0.7941176470588235, 'f1-score': 0.7341772151898734, 'fairness': 0.14583333333333337, 'TPR_protected': 0.5769230769230769, 'TPR_non_protected': 0.671875, 'TNR_protected': 0.8717948717948718, 'TNR_non_protected': 0.9333333333333333}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.7783625730994153, 'accuracy': 0.7941176470588235, 'f1-score': 0.7341772151898734, 'fairness': 0.06153846153846153, 'TPR_protected': 0.5769230769230769, 'TPR_non_protected': 0.671875, 'TNR_protected': 0.8717948717948718, 'TNR_non_protected': 0.9333333333333333}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.7783625730994153, 'accuracy': 0.7941176470588235, 'f1-score': 0.7341772151898734, 'fairness': -2.0, 'TPR_protected': 0.5769230769230769, 'TPR_non_protected': 0.671875, 'TNR_protected': 0.8717948717948718, 'TNR_non_protected': 0.9333333333333333}\n"
     ]
    }
   ],
   "source": [
    "run_eval('credit-approval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 30000\n",
      "Number of attribute: 24\n",
      "Length (cleaned): 30000\n",
      "Class imbalance: \n",
      " 0    23364\n",
      "1     6636\n",
      "Name: default payment, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.5030307861781076, 'accuracy': 0.4791111111111111, 'f1-score': 0.31321418107237037, 'fairness': 0.006063677866650963}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.5030307861781076, 'accuracy': 0.4791111111111111, 'f1-score': 0.31321418107237037, 'fairness': 0.014832700931355691, 'TPR_protected': 0.5390134529147982, 'TPR_non_protected': 0.5538461538461539, 'TNR_protected': 0.46197051252047744, 'TNR_non_protected': 0.45861944344054933}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.5030307861781076, 'accuracy': 0.4791111111111111, 'f1-score': 0.31321418107237037, 'fairness': 0.03080541621356156, 'TPR_protected': 0.5390134529147982, 'TPR_non_protected': 0.5538461538461539, 'TNR_protected': 0.46197051252047744, 'TNR_non_protected': 0.45861944344054933}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.5030307861781076, 'accuracy': 0.4791111111111111, 'f1-score': 0.31321418107237037, 'fairness': 0.003351069079928104, 'TPR_protected': 0.5390134529147982, 'TPR_non_protected': 0.5538461538461539, 'TNR_protected': 0.46197051252047744, 'TNR_non_protected': 0.45861944344054933}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.5030307861781076, 'accuracy': 0.4791111111111111, 'f1-score': 0.31321418107237037, 'fairness': -0.0280934242612014, 'TPR_protected': 0.5390134529147982, 'TPR_non_protected': 0.5538461538461539, 'TNR_protected': 0.46197051252047744, 'TNR_non_protected': 0.45861944344054933}\n"
     ]
    }
   ],
   "source": [
    "run_eval('credit-card')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 8755\n",
      "Number of attribute: 18\n",
      "Length (cleaned): 8755\n",
      "Class imbalance: \n",
      " 1    8059\n",
      "0     696\n",
      "Name: label, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.9127265807386796, 'accuracy': 0.9596497906357061, 'f1-score': 0.9777123633305299, 'fairness': 0.03755094444961382}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.9127265807386796, 'accuracy': 0.9596497906357061, 'f1-score': 0.9777123633305299, 'fairness': 0.010147956272325787, 'TPR_protected': 0.9657027572293208, 'TPR_non_protected': 0.9758507135016465, 'TNR_protected': 0.8650306748466258, 'TNR_non_protected': 0.8333333333333334}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.9127265807386796, 'accuracy': 0.9596497906357061, 'f1-score': 0.9777123633305299, 'fairness': 0.0028669410150891084, 'TPR_protected': 0.9657027572293208, 'TPR_non_protected': 0.9758507135016465, 'TNR_protected': 0.8650306748466258, 'TNR_non_protected': 0.8333333333333334}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.9127265807386796, 'accuracy': 0.9596497906357061, 'f1-score': 0.9777123633305299, 'fairness': 0.031697341513292426, 'TPR_protected': 0.9657027572293208, 'TPR_non_protected': 0.9758507135016465, 'TNR_protected': 0.8650306748466258, 'TNR_non_protected': 0.8333333333333334}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.9127265807386796, 'accuracy': 0.9596497906357061, 'f1-score': 0.9777123633305299, 'fairness': 0.31818181818181834, 'TPR_protected': 0.9657027572293208, 'TPR_non_protected': 0.9758507135016465, 'TNR_protected': 0.8650306748466258, 'TNR_non_protected': 0.8333333333333334}\n"
     ]
    }
   ],
   "source": [
    "run_eval('credit-scoring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 1000\n",
      "Number of attribute: 22\n",
      "Length (cleaned): 1000\n",
      "Class imbalance: \n",
      " 1    700\n",
      "0    300\n",
      "Name: class-label, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.64056995635943, 'accuracy': 0.7066666666666667, 'f1-score': 0.7934272300469484, 'fairness': -0.11813893653516294}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.64056995635943, 'accuracy': 0.7066666666666667, 'f1-score': 0.7934272300469484, 'fairness': 0.12497175141242944, 'TPR_protected': 0.8983050847457628, 'TPR_non_protected': 0.7733333333333333, 'TNR_protected': 0.3793103448275862, 'TNR_non_protected': 0.5161290322580645}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.64056995635943, 'accuracy': 0.7066666666666667, 'f1-score': 0.7934272300469484, 'fairness': 0.04804167470576881, 'TPR_protected': 0.8983050847457628, 'TPR_non_protected': 0.7733333333333333, 'TNR_protected': 0.3793103448275862, 'TNR_non_protected': 0.5161290322580645}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.64056995635943, 'accuracy': 0.7066666666666667, 'f1-score': 0.7934272300469484, 'fairness': 0.13681868743047831, 'TPR_protected': 0.8983050847457628, 'TPR_non_protected': 0.7733333333333333, 'TNR_protected': 0.3793103448275862, 'TNR_non_protected': 0.5161290322580645}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.64056995635943, 'accuracy': 0.7066666666666667, 'f1-score': 0.7934272300469484, 'fairness': -0.8, 'TPR_protected': 0.8983050847457628, 'TPR_non_protected': 0.7733333333333333, 'TNR_protected': 0.3793103448275862, 'TNR_non_protected': 0.5161290322580645}\n"
     ]
    }
   ],
   "source": [
    "run_eval('german-credit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 50000\n",
      "Number of attribute: 47\n",
      "Length (cleaned): 38896\n",
      "Class imbalance: \n",
      " 0    28747\n",
      "1    10149\n",
      "Name: TARGET_LABEL_BAD, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.5089792828300436, 'accuracy': 0.7259405261804782, 'f1-score': 0.08471665712650259, 'fairness': -0.0013000085763060151}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.5089792828300436, 'accuracy': 0.7259405261804782, 'f1-score': 0.08471665712650259, 'fairness': 0.01480856951380332, 'TPR_protected': 0.05402425578831312, 'TPR_non_protected': 0.0392156862745098, 'TNR_protected': 0.9712081294693263, 'TNR_non_protected': 0.968156766687079}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.5089792828300436, 'accuracy': 0.7259405261804782, 'f1-score': 0.08471665712650259, 'fairness': 0.0657629223366275, 'TPR_protected': 0.05402425578831312, 'TPR_non_protected': 0.0392156862745098, 'TNR_protected': 0.9712081294693263, 'TNR_non_protected': 0.968156766687079}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.5089792828300436, 'accuracy': 0.7259405261804782, 'f1-score': 0.08471665712650259, 'fairness': 0.003051362782247314, 'TPR_protected': 0.05402425578831312, 'TPR_non_protected': 0.0392156862745098, 'TNR_protected': 0.9712081294693263, 'TNR_non_protected': 0.968156766687079}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.5089792828300436, 'accuracy': 0.7259405261804782, 'f1-score': 0.08471665712650259, 'fairness': -0.5631598793363501, 'TPR_protected': 0.05402425578831312, 'TPR_non_protected': 0.0392156862745098, 'TNR_protected': 0.9712081294693263, 'TNR_non_protected': 0.968156766687079}\n"
     ]
    }
   ],
   "source": [
    "run_eval('PAKDD')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "07f77a1088ec27c511ada81280526a5a9813c372362ef5dc18ab18682e528864"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
