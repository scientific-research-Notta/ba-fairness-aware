{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "2023-03-07 00:59:49.857547: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 00:59:49.857568: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#Import lib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from my_useful_functions import calculate_performance_statistical_parity,calculate_performance_equalized_odds,calculate_performance_equal_opportunity,calculate_performance_predictive_parity,calculate_performance_predictive_equality,calculate_performance_treatment_equality\n",
    "from sklearn import preprocessing\n",
    "#Adafair\n",
    "from AdaFair import AdaFair \n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from compute_abroca import *\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics \n",
    "from scipy import interpolate\n",
    "from scipy import integrate\n",
    "from disparate_impact_remover import DisparateImpactRemover\n",
    "from aif360.datasets.binary_label_dataset import BinaryLabelDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://archive.ics.uci.edu/ml/datasets/credit+approval\n",
    "#http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html\n",
    "#https://www.kaggle.com/code/chandanabhatt/prediction-of-credit-approval\n",
    "# Credit approval dataset\n",
    "# $ Male          : num  1 1 0 0 0 0 1 0 0 0 ...\n",
    "# $ Age           : chr  \"58.67\" \"24.50\" \"27.83\" \"20.17\" ...\n",
    "# $ Debt          : num  4.46 0.5 1.54 5.62 4 ...\n",
    "# $ Married       : chr  \"u\" \"u\" \"u\" \"u\" ...\n",
    "# $ BankCustomer  : chr  \"g\" \"g\" \"g\" \"g\" ...\n",
    "# $ EducationLevel: chr  \"q\" \"q\" \"w\" \"w\" ...\n",
    "# $ Ethnicity     : chr  \"h\" \"h\" \"v\" \"v\" ...\n",
    "# $ YearsEmployed : num  3.04 1.5 3.75 1.71 2.5 ...\n",
    "# $ PriorDefault  : num  1 1 1 1 1 1 1 1 1 0 ...\n",
    "# $ Employed      : num  1 0 1 0 0 0 0 0 0 0 ...\n",
    "# $ CreditScore   : num  6 0 5 0 0 0 0 0 0 0 ...\n",
    "# $ DriversLicense: chr  \"f\" \"f\" \"t\" \"f\" ...\n",
    "# $ Citizen       : chr  \"g\" \"g\" \"g\" \"s\" ...\n",
    "# $ ZipCode       : chr  \"00043\" \"00280\" \"00100\" \"00120\" ...\n",
    "# $ Income        : num  560 824 3 0 0 ...\n",
    "# $ Approved      : chr  \"+\" \"+\" \"+\" \"+\" ...\n",
    "\n",
    "def load_credit_approval():\n",
    "    df = pd.read_csv('data/credit-approval.data',sep=\",\")\n",
    "    protected_attribute = 'Male'\n",
    "    majority_group_name = \"Female\"\n",
    "    minority_group_name = \"Male\"\n",
    "    class_label = 'Approved'\n",
    "    filename = \"DIR_Ada.credit_approval.abroca.png\"\n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    #Remove missing value\n",
    "    df = df[df['Male'] != '?']   \n",
    "    #Label sex\n",
    "    df['Male']=[\"Female\" if v == \"a\" else \"Male\" for v in df['Male']]\n",
    "    #Label class\n",
    "    df['Approved']=[1 if v == \"+\" else 0 for v in df['Approved']]\n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X, y,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit card client\n",
    "#Gender (1 = male; 2 = female)\n",
    "def load_credit_card():\n",
    "    df = pd.read_csv('data/credit-card-clients.csv')    \n",
    "    protected_attribute = 'SEX'\n",
    "    majority_group_name = \"Male\"\n",
    "    minority_group_name = \"Female\"\n",
    "    class_label = 'default payment'\n",
    "    filename = \"DIR_Ada.credit_card.abroca.png\"   \n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    \n",
    "    #Label sex\n",
    "    df['SEX']=[\"Female\" if v == 2 else \"Male\" for v in df['SEX']]\n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    \n",
    "    #label encode\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X, y,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#German credit\n",
    "def load_german_credit():\n",
    "    df = pd.read_csv('data/german_data_credit.csv')    \n",
    "    protected_attribute = 'sex'\n",
    "    majority_group_name = \"male\"\n",
    "    minority_group_name = \"female\"\n",
    "    class_label = 'class-label'\n",
    "    filename = \"DIR_Ada.german_credit.abroca.png\"    \n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    #label encode\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X, y,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_PAKDD2010():\n",
    "    df = pd.read_csv('data/PAKDD.csv')    \n",
    "    protected_attribute = 'SEX'\n",
    "    majority_group_name = \"Male\"\n",
    "    minority_group_name = \"Female\"\n",
    "    class_label = 'TARGET_LABEL_BAD'\n",
    "    filename = \"DIR_Ada.PAKDD.abroca.png\"    \n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    \n",
    "    #Remove ID\n",
    "    df=df.drop(columns=['ID_CLIENT'])\n",
    "    df =df.dropna()\n",
    "    df=df.drop(columns = ['RESIDENCIAL_PHONE_AREA_CODE','RESIDENCIAL_ZIP_3','PROFESSIONAL_ZIP_3'])\n",
    "    #Label sex\n",
    "    df['SEX']=[\"Female\" if v == \"F\" else \"Male\" for v in df['SEX']]\n",
    "    \n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    \n",
    "    #label encode\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X, y,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit scoring data\n",
    "#https://www.kaggle.com/code/islombekdavronov/credit-scoring\n",
    "#FinTech companies in Central Asia.\n",
    "def load_credit_scoring():\n",
    "    df = pd.read_csv('data/credit_scoring.csv')    \n",
    "    protected_attribute = 'Sex'\n",
    "    majority_group_name = \"Male\"\n",
    "    minority_group_name = \"Female\"\n",
    "    class_label = 'label'\n",
    "    filename = \"DIR_Ada.credit_scoring.abroca.png\"    \n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    \n",
    "    df = df.replace({'-':0})\n",
    "    df['Score_point']=df['Score_point'].astype(float)\n",
    "    \n",
    "       \n",
    "    #Label sex\n",
    "    df['Sex']=[\"Female\" if v == 2 else \"Male\" for v in df['Sex']]\n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    \n",
    "    #label encode\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,1:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X, y,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X, y, sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name):    \n",
    "      \n",
    "    #Run Reductions model\n",
    "    #clf = LogisticRegression(random_state=0)\n",
    "    #clf = tree.DecisionTreeClassifier(random_state=0)\n",
    "    dataset = BinaryLabelDataset(df=pd.concat([X, y.to_frame()], axis=1), label_names=[y.name], protected_attribute_names=[protected_attribute])\n",
    "    # Apply DisparateImpactRemover\n",
    "    DisparateImpact = DisparateImpactRemover(sensitive_attribute=protected_attribute)\n",
    "    dataset_transf = DisparateImpact.fit_transform(dataset)\n",
    "\n",
    "    # Convert the BinaryLabelDataset back to a pandas dataframe\n",
    "    data = dataset_transf.convert_to_dataframe()[0]\n",
    "\n",
    "    length = len(data.columns)\n",
    "    X_transf = data.iloc[:,:length-1]\n",
    "    y_transf = data[y.name].astype(int)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transf, y_transf, test_size=0.3, random_state=42) \n",
    "\n",
    "    Ada = AdaFair(n_estimators=50, saIndex=sa_index, saValue=p_Group, CSB=\"CSB2\", c=1, use_validation=False)\n",
    "    Ada.fit(X_train,y_train)\n",
    "    y_predicts = Ada.predict(X_test)\n",
    "    y_pred_probs = Ada.predict_proba(X_test)\n",
    "        \n",
    "    #Print measures\n",
    "        \n",
    "    print(\"Statistical parity:\")\n",
    "    print(calculate_performance_statistical_parity(X_test.values, y_test.values, y_predicts, sa_index, p_Group))\n",
    "         \n",
    "    print(\"Equal opportunity\")\n",
    "    print(calculate_performance_equal_opportunity(X_test.values, y_test.values, y_predicts,  sa_index, p_Group))\n",
    "        \n",
    "    print(\"Equalized odds\")\n",
    "    print(calculate_performance_equalized_odds(X_test.values, y_test.values, y_predicts, y_pred_probs, sa_index, p_Group))\n",
    "         \n",
    "    print(\"Predictive parity\")\n",
    "    print(calculate_performance_predictive_parity(X_test.values, y_test.values, y_predicts,  sa_index, p_Group))\n",
    "        \n",
    "    print(\"Predictive equality\")\n",
    "    print(calculate_performance_predictive_equality(X_test.values, y_test.values, y_predicts,  sa_index, p_Group))\n",
    "        \n",
    "    print(\"Treatment equality\")\n",
    "    print(calculate_performance_treatment_equality(X_test.values, y_test.values, y_predicts,  sa_index, p_Group))\n",
    "        \n",
    "    # \n",
    "    \n",
    "    #make predictions\n",
    "    X_test['pred_proba'] = Ada.predict_proba(X_test)[:,1:2]\n",
    "    X_test['true_label'] = y_test\n",
    "    df_test = X_test\n",
    "    \n",
    "    \n",
    "    #Compute Abroca\n",
    "    slice = compute_abroca(df_test, pred_col = 'pred_proba' , label_col = 'true_label', protected_attr_col = protected_attribute,\n",
    "                           majority_protected_attr_val = 1, n_grid = 10000,\n",
    "                           plot_slices = True, majority_group_name=majority_group_name ,minority_group_name=minority_group_name,file_name = filename)\n",
    "    print(\"ABROCA:\",slice)\n",
    "    plt.clf() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function\n",
    "def run_eval(dataset):\n",
    "    if dataset == 'credit-approval':\n",
    "        X, y,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_credit_approval()\n",
    "        run_experiment(X, y,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                        \n",
    "    if dataset == 'credit-card':\n",
    "        X, y,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_credit_card()\n",
    "        run_experiment(X, y,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                        \n",
    "    if dataset == 'german-credit':\n",
    "        X, y,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_german_credit()\n",
    "        run_experiment(X, y,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                            \n",
    "    if dataset == 'PAKDD':\n",
    "        X, y,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_PAKDD2010()\n",
    "        run_experiment(X, y,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                                                \n",
    "    if dataset == 'credit-scoring':\n",
    "        X, y,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_credit_scoring()\n",
    "        run_experiment(X, y, sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                                                        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 690\n",
      "Number of attribute: 16\n",
      "Length (cleaned): 678\n",
      "Class imbalance: \n",
      " 0    374\n",
      "1    304\n",
      "Name: Approved, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.8538011695906433, 'accuracy': 0.8431372549019608, 'f1-score': 0.8415841584158414, 'fairness': 0.06065301604869955}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.8538011695906433, 'accuracy': 0.8431372549019608, 'f1-score': 0.8415841584158414, 'fairness': 0.024038461538461564, 'TPR_protected': 0.9615384615384616, 'TPR_non_protected': 0.9375, 'TNR_protected': 0.7948717948717948, 'TNR_non_protected': 0.7466666666666667}\n",
      "Equalized odds\n",
      "{'balanced_accuracy': 0.8538011695906433, 'accuracy': 0.8431372549019608, 'f1-score': 0.8415841584158414, 'fairness': 0.07224358974358969, 'TPR_protected': 0.9615384615384616, 'TPR_non_protected': 0.9375, 'TNR_protected': 0.7948717948717948, 'TNR_non_protected': 0.7466666666666667}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.8538011695906433, 'accuracy': 0.8431372549019608, 'f1-score': 0.8415841584158414, 'fairness': 0.001917913310318431, 'TPR_protected': 0.9615384615384616, 'TPR_non_protected': 0.9375, 'TNR_protected': 0.7948717948717948, 'TNR_non_protected': 0.7466666666666667}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.8538011695906433, 'accuracy': 0.8431372549019608, 'f1-score': 0.8415841584158414, 'fairness': 0.048205128205128234, 'TPR_protected': 0.9615384615384616, 'TPR_non_protected': 0.9375, 'TNR_protected': 0.7948717948717948, 'TNR_non_protected': 0.7466666666666667}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.8538011695906433, 'accuracy': 0.8431372549019608, 'f1-score': 0.8415841584158414, 'fairness': -0.08552631578947367, 'TPR_protected': 0.9615384615384616, 'TPR_non_protected': 0.9375, 'TNR_protected': 0.7948717948717948, 'TNR_non_protected': 0.7466666666666667}\n",
      "ABROCA: 0.03612179438188301\n"
     ]
    }
   ],
   "source": [
    "run_eval('credit-approval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 30000\n",
      "Number of attribute: 24\n",
      "Length (cleaned): 30000\n",
      "Class imbalance: \n",
      " 0    23364\n",
      "1     6636\n",
      "Name: default payment, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.6391972982374767, 'accuracy': 0.82, 'f1-score': 0.4355400696864111, 'fairness': 0.004525868979176076}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.6391972982374767, 'accuracy': 0.82, 'f1-score': 0.4355400696864111, 'fairness': 0.03422400297184702, 'TPR_protected': 0.33363228699551567, 'TPR_non_protected': 0.29940828402366865, 'TNR_protected': 0.9618534987128481, 'TNR_non_protected': 0.9559089266353451}\n",
      "Equalized odds\n",
      "{'balanced_accuracy': 0.6391972982374767, 'accuracy': 0.82, 'f1-score': 0.4355400696864111, 'fairness': 0.04016857504935001, 'TPR_protected': 0.33363228699551567, 'TPR_non_protected': 0.29940828402366865, 'TNR_protected': 0.9618534987128481, 'TNR_non_protected': 0.9559089266353451}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.6391972982374767, 'accuracy': 0.82, 'f1-score': 0.4355400696864111, 'fairness': 0.02066043613707169, 'TPR_protected': 0.33363228699551567, 'TPR_non_protected': 0.29940828402366865, 'TNR_protected': 0.9618534987128481, 'TNR_non_protected': 0.9559089266353451}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.6391972982374767, 'accuracy': 0.82, 'f1-score': 0.4355400696864111, 'fairness': 0.005944572077502978, 'TPR_protected': 0.33363228699551567, 'TPR_non_protected': 0.29940828402366865, 'TNR_protected': 0.9618534987128481, 'TNR_non_protected': 0.9559089266353451}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.6391972982374767, 'accuracy': 0.82, 'f1-score': 0.4355400696864111, 'fairness': -0.29417680780448574, 'TPR_protected': 0.33363228699551567, 'TPR_non_protected': 0.29940828402366865, 'TNR_protected': 0.9618534987128481, 'TNR_non_protected': 0.9559089266353451}\n",
      "ABROCA: 0.02008428126052672\n"
     ]
    }
   ],
   "source": [
    "run_eval('credit-card')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 1000\n",
      "Number of attribute: 22\n",
      "Length (cleaned): 1000\n",
      "Class imbalance: \n",
      " 1    700\n",
      "0    300\n",
      "Name: class-label, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.6966666666666667, 'f1-score': 0.8212180746561886, 'fairness': 0.0}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.6966666666666667, 'f1-score': 0.8212180746561886, 'fairness': 0.0, 'TPR_protected': 1.0, 'TPR_non_protected': 1.0, 'TNR_protected': 0.0, 'TNR_non_protected': 0.0}\n",
      "Equalized odds\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.6966666666666667, 'f1-score': 0.8212180746561886, 'fairness': 0.0, 'TPR_protected': 1.0, 'TPR_non_protected': 1.0, 'TNR_protected': 0.0, 'TNR_non_protected': 0.0}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.6966666666666667, 'f1-score': 0.8212180746561886, 'fairness': 0.037092624356775294, 'TPR_protected': 1.0, 'TPR_non_protected': 1.0, 'TNR_protected': 0.0, 'TNR_non_protected': 0.0}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.6966666666666667, 'f1-score': 0.8212180746561886, 'fairness': 0.0, 'TPR_protected': 1.0, 'TPR_non_protected': 1.0, 'TNR_protected': 0.0, 'TNR_non_protected': 0.0}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.6966666666666667, 'f1-score': 0.8212180746561886, 'fairness': 0.0, 'TPR_protected': 1.0, 'TPR_non_protected': 1.0, 'TNR_protected': 0.0, 'TNR_non_protected': 0.0}\n",
      "ABROCA: 0.05343922204798221\n"
     ]
    }
   ],
   "source": [
    "run_eval('german-credit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 50000\n",
      "Number of attribute: 47\n",
      "Length (cleaned): 38896\n",
      "Class imbalance: \n",
      " 0    28747\n",
      "1    10149\n",
      "Name: TARGET_LABEL_BAD, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.7352815151255463, 'f1-score': 0.0, 'fairness': 0.0}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.7352815151255463, 'f1-score': 0.0, 'fairness': 0.0, 'TPR_protected': 0.0, 'TPR_non_protected': 0.0, 'TNR_protected': 1.0, 'TNR_non_protected': 1.0}\n",
      "Equalized odds\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.7352815151255463, 'f1-score': 0.0, 'fairness': 0.0, 'TPR_protected': 0.0, 'TPR_non_protected': 0.0, 'TNR_protected': 1.0, 'TNR_non_protected': 1.0}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.7352815151255463, 'f1-score': 0.0, 'fairness': 0.0, 'TPR_protected': 0.0, 'TPR_non_protected': 0.0, 'TNR_protected': 1.0, 'TNR_non_protected': 1.0}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.7352815151255463, 'f1-score': 0.0, 'fairness': 0.0, 'TPR_protected': 0.0, 'TPR_non_protected': 0.0, 'TNR_protected': 1.0, 'TNR_non_protected': 1.0}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.7352815151255463, 'f1-score': 0.0, 'fairness': nan, 'TPR_protected': 0.0, 'TPR_non_protected': 0.0, 'TNR_protected': 1.0, 'TNR_non_protected': 1.0}\n",
      "ABROCA: 0.01413606234849289\n"
     ]
    }
   ],
   "source": [
    "run_eval('PAKDD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 8755\n",
      "Number of attribute: 18\n",
      "Length (cleaned): 8755\n",
      "Class imbalance: \n",
      " 1    8059\n",
      "0     696\n",
      "Name: label, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.9927140885235513, 'accuracy': 0.9939094023601066, 'f1-score': 0.9966555183946487, 'fairness': 0.03198846189634319}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.9927140885235513, 'accuracy': 0.9939094023601066, 'f1-score': 0.9966555183946487, 'fairness': 0.0023341701995412967, 'TPR_protected': 0.9932750504371217, 'TPR_non_protected': 0.995609220636663, 'TNR_protected': 0.9877300613496932, 'TNR_non_protected': 1.0}\n",
      "Equalized odds\n",
      "{'balanced_accuracy': 0.9927140885235513, 'accuracy': 0.9939094023601066, 'f1-score': 0.9966555183946487, 'fairness': 0.014604108849848085, 'TPR_protected': 0.9932750504371217, 'TPR_non_protected': 0.995609220636663, 'TNR_protected': 0.9877300613496932, 'TNR_non_protected': 1.0}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.9927140885235513, 'accuracy': 0.9939094023601066, 'f1-score': 0.9966555183946487, 'fairness': 0.0013522650439485862, 'TPR_protected': 0.9932750504371217, 'TPR_non_protected': 0.995609220636663, 'TNR_protected': 0.9877300613496932, 'TNR_non_protected': 1.0}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.9927140885235513, 'accuracy': 0.9939094023601066, 'f1-score': 0.9966555183946487, 'fairness': 0.012269938650306749, 'TPR_protected': 0.9932750504371217, 'TPR_non_protected': 0.995609220636663, 'TNR_protected': 0.9877300613496932, 'TNR_non_protected': 1.0}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.9927140885235513, 'accuracy': 0.9939094023601066, 'f1-score': 0.9966555183946487, 'fairness': -inf, 'TPR_protected': 0.9932750504371217, 'TPR_non_protected': 0.995609220636663, 'TNR_protected': 0.9877300613496932, 'TNR_non_protected': 1.0}\n",
      "ABROCA: 0.007302141413460429\n"
     ]
    }
   ],
   "source": [
    "run_eval('credit-scoring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "07f77a1088ec27c511ada81280526a5a9813c372362ef5dc18ab18682e528864"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
