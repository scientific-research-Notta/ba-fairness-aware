{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n",
      "2023-03-07 01:50:04.673049: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 01:50:04.673089: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#Import lib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from my_useful_functions import calculate_performance_statistical_parity,calculate_performance_equalized_odds,calculate_performance_equal_opportunity,calculate_performance_predictive_parity,calculate_performance_predictive_equality,calculate_performance_treatment_equality\n",
    "from sklearn import preprocessing\n",
    "from AdaFair import AdaFair \n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from compute_abroca import *\n",
    "from eq_odds_postprocessing import EqOddsPostprocessing\n",
    "from aif360.datasets.binary_label_dataset import BinaryLabelDataset\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics \n",
    "from scipy import interpolate\n",
    "from scipy import integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://archive.ics.uci.edu/ml/datasets/credit+approval\n",
    "#http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html\n",
    "#https://www.kaggle.com/code/chandanabhatt/prediction-of-credit-approval\n",
    "# Credit approval dataset\n",
    "# $ Male          : num  1 1 0 0 0 0 1 0 0 0 ...\n",
    "# $ Age           : chr  \"58.67\" \"24.50\" \"27.83\" \"20.17\" ...\n",
    "# $ Debt          : num  4.46 0.5 1.54 5.62 4 ...\n",
    "# $ Married       : chr  \"u\" \"u\" \"u\" \"u\" ...\n",
    "# $ BankCustomer  : chr  \"g\" \"g\" \"g\" \"g\" ...\n",
    "# $ EducationLevel: chr  \"q\" \"q\" \"w\" \"w\" ...\n",
    "# $ Ethnicity     : chr  \"h\" \"h\" \"v\" \"v\" ...\n",
    "# $ YearsEmployed : num  3.04 1.5 3.75 1.71 2.5 ...\n",
    "# $ PriorDefault  : num  1 1 1 1 1 1 1 1 1 0 ...\n",
    "# $ Employed      : num  1 0 1 0 0 0 0 0 0 0 ...\n",
    "# $ CreditScore   : num  6 0 5 0 0 0 0 0 0 0 ...\n",
    "# $ DriversLicense: chr  \"f\" \"f\" \"t\" \"f\" ...\n",
    "# $ Citizen       : chr  \"g\" \"g\" \"g\" \"s\" ...\n",
    "# $ ZipCode       : chr  \"00043\" \"00280\" \"00100\" \"00120\" ...\n",
    "# $ Income        : num  560 824 3 0 0 ...\n",
    "# $ Approved      : chr  \"+\" \"+\" \"+\" \"+\" ...\n",
    "\n",
    "def load_credit_approval():\n",
    "    df = pd.read_csv('data/credit-approval.data',sep=\",\")\n",
    "    protected_attribute = 'Male'\n",
    "    majority_group_name = \"Female\"\n",
    "    minority_group_name = \"Male\"\n",
    "    class_label = 'Approved'\n",
    "    filename = \"EOP_Ada.credit_approval.abroca.png\"\n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    #Remove missing value\n",
    "    df = df[df['Male'] != '?']   \n",
    "    #Label sex\n",
    "    df['Male']=[\"Female\" if v == \"a\" else \"Male\" for v in df['Male']]\n",
    "    #Label class\n",
    "    df['Approved']=[1 if v == \"+\" else 0 for v in df['Approved']]\n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit card client\n",
    "#Gender (1 = male; 2 = female)\n",
    "def load_credit_card():\n",
    "    df = pd.read_csv('data/credit-card-clients.csv')    \n",
    "    protected_attribute = 'SEX'\n",
    "    majority_group_name = \"Male\"\n",
    "    minority_group_name = \"Female\"\n",
    "    class_label = 'default payment'\n",
    "    filename = \"EOP_Ada.credit_card.abroca.png\"   \n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    \n",
    "    #Label sex\n",
    "    df['SEX']=[\"Female\" if v == 2 else \"Male\" for v in df['SEX']]\n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    \n",
    "    #label encode\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#German credit\n",
    "def load_german_credit():\n",
    "    df = pd.read_csv('data/german_data_credit.csv')    \n",
    "    protected_attribute = 'sex'\n",
    "    majority_group_name = \"male\"\n",
    "    minority_group_name = \"female\"\n",
    "    class_label = 'class-label'\n",
    "    filename = \"EOP_Ada.german_credit.abroca.png\"    \n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    #label encode\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_PAKDD2010():\n",
    "    df = pd.read_csv('data/PAKDD.csv')    \n",
    "    protected_attribute = 'SEX'\n",
    "    majority_group_name = \"Male\"\n",
    "    minority_group_name = \"Female\"\n",
    "    class_label = 'TARGET_LABEL_BAD'\n",
    "    filename = \"EOP_Ada.PAKDD.abroca.png\"    \n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    \n",
    "    #Remove ID\n",
    "    df=df.drop(columns=['ID_CLIENT'])\n",
    "    df =df.dropna()\n",
    "    df=df.drop(columns = ['RESIDENCIAL_PHONE_AREA_CODE','RESIDENCIAL_ZIP_3','PROFESSIONAL_ZIP_3'])\n",
    "    #Label sex\n",
    "    df['SEX']=[\"Female\" if v == \"F\" else \"Male\" for v in df['SEX']]\n",
    "    \n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    \n",
    "    #label encode\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit scoring data\n",
    "#https://www.kaggle.com/code/islombekdavronov/credit-scoring\n",
    "#FinTech companies in Central Asia.\n",
    "def load_credit_scoring():\n",
    "    df = pd.read_csv('data/credit_scoring.csv')    \n",
    "    protected_attribute = 'Sex'\n",
    "    majority_group_name = \"Male\"\n",
    "    minority_group_name = \"Female\"\n",
    "    class_label = 'label'\n",
    "    filename = \"EOP_Ada.credit_scoring.abroca.png\"    \n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    \n",
    "    df = df.replace({'-':0})\n",
    "    df['Score_point']=df['Score_point'].astype(float)\n",
    "    \n",
    "       \n",
    "    #Label sex\n",
    "    df['Sex']=[\"Female\" if v == 2 else \"Male\" for v in df['Sex']]\n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    \n",
    "    #label encode\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,1:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,sa_index, p_Group, protected_attribute, filename,majority_group_name,minority_group_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name):    \n",
    "      \n",
    "    #Run DT model, thay doi ca proba ca predict lieu co dung ?\n",
    "    Ada = AdaFair(n_estimators=50, saIndex=sa_index, saValue=p_Group, CSB=\"CSB2\", c=1, use_validation=False)\n",
    "    Ada.fit(X_train,y_train)\n",
    "    y_predicts = Ada.predict(X_test)\n",
    "    y_pred_probs = Ada.predict_proba(X_test)\n",
    "\n",
    "    X_predicts = X_test.copy()\n",
    "\n",
    "    X_predicts[y_test.name] = y_predicts\n",
    "\n",
    "    privileged_groups = [{protected_attribute: 1.0}]\n",
    "    unprivileged_groups = [{protected_attribute: 0.0}]\n",
    "    eop = EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=42)\n",
    "    #Create true dataset and pred dataset\n",
    "    dataset_true = BinaryLabelDataset(df=pd.concat([X_test, y_test.to_frame()], axis=1), label_names=[y_test.name], protected_attribute_names=[protected_attribute])\n",
    "    dataset_predicts = BinaryLabelDataset(df=X_predicts, label_names=[y_test.name], protected_attribute_names=[protected_attribute])\n",
    "    # dataset_pred_proba = BinaryLabelDataset(df=X_pred_proba, label_names=[y_test.name], protected_attribute_names=[protected_attribute])\n",
    "\n",
    "    dataset_predicts_transf = eop.fit_predict(dataset_true=dataset_true, dataset_pred=dataset_predicts)\n",
    "    # dataset_pred_proba_transf = eop.fit_predict(dataset_true=dataset_true, dataset_pred=dataset_pred_proba)\n",
    "\n",
    "    data_predicts = dataset_predicts_transf.convert_to_dataframe()[0]\n",
    "    # data_pred_proba = dataset_pred_proba_transf.convert_to_dataframe()[0]\n",
    "\n",
    "    y_transf_predicts = data_predicts[y_test.name].astype(int)\n",
    "    # y_transf_pred_proba = data_pred_proba[y_test.name].astype(int)\n",
    "        \n",
    "    #Print measures, use new pred instead of old pred\n",
    "        \n",
    "    print(\"Statistical parity:\")\n",
    "    print(calculate_performance_statistical_parity(X_test.values, y_test.values, y_transf_predicts.values, sa_index, p_Group))\n",
    "         \n",
    "    print(\"Equal opportunity\")\n",
    "    print(calculate_performance_equal_opportunity(X_test.values, y_test.values, y_transf_predicts.values,  sa_index, p_Group))\n",
    "        \n",
    "    # print(\"Equalized odds\")\n",
    "    # # print(calculate_performance_equalized_odds(X_test.values, y_test.values, y_transf_predicts.values, y_transf_pred_proba.values, sa_index, p_Group))\n",
    "    # print(calculate_performance_equalized_odds(X_test.values, y_test.values, y_transf_predicts.values, y_transf_predicts.values, sa_index, p_Group))\n",
    "         \n",
    "    print(\"Predictive parity\")\n",
    "    print(calculate_performance_predictive_parity(X_test.values, y_test.values, y_transf_predicts.values,  sa_index, p_Group))\n",
    "        \n",
    "    print(\"Predictive equality\")\n",
    "    print(calculate_performance_predictive_equality(X_test.values, y_test.values, y_transf_predicts.values,  sa_index, p_Group))\n",
    "        \n",
    "    print(\"Treatment equality\")\n",
    "    print(calculate_performance_treatment_equality(X_test.values, y_test.values, y_transf_predicts.values,  sa_index, p_Group))\n",
    "        \n",
    "    # \n",
    "    \n",
    "    #make predictions\n",
    "    # X_test['pred_proba'] = y_transf_predicts.values\n",
    "    # X_test['true_label'] = y_test\n",
    "    # df_test = X_test\n",
    "    \n",
    "    # #Compute Abroca\n",
    "    # slice = compute_abroca(df_test, pred_col = 'pred_proba' , label_col = 'true_label', protected_attr_col = protected_attribute,\n",
    "    #                        majority_protected_attr_val = 1, n_grid = 10000,\n",
    "    #                        plot_slices = True, majority_group_name=majority_group_name ,minority_group_name=minority_group_name,file_name = filename)\n",
    "    # print(\"ABROCA:\",slice)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function\n",
    "def run_eval(dataset):\n",
    "    if dataset == 'credit-approval':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_credit_approval()\n",
    "        run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                        \n",
    "    if dataset == 'credit-card':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_credit_card()\n",
    "        run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                        \n",
    "    if dataset == 'german-credit':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_german_credit()\n",
    "        run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                            \n",
    "    if dataset == 'PAKDD':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_PAKDD2010()\n",
    "        run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                                                \n",
    "    if dataset == 'credit-scoring':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name = load_credit_scoring()\n",
    "        run_experiment(X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,filename,majority_group_name,minority_group_name)                                                                        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 690\n",
      "Number of attribute: 16\n",
      "Length (cleaned): 678\n",
      "Class imbalance: \n",
      " 0    374\n",
      "1    304\n",
      "Name: Approved, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.8450292397660819, 'accuracy': 0.8333333333333334, 'f1-score': 0.8333333333333331, 'fairness': 0.029883785279468777}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.8450292397660819, 'accuracy': 0.8333333333333334, 'f1-score': 0.8333333333333331, 'fairness': 0.024038461538461564, 'TPR_protected': 0.9615384615384616, 'TPR_non_protected': 0.9375, 'TNR_protected': 0.7435897435897436, 'TNR_non_protected': 0.7466666666666667}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.8450292397660819, 'accuracy': 0.8333333333333334, 'f1-score': 0.8333333333333331, 'fairness': 0.0452079566003617, 'TPR_protected': 0.9615384615384616, 'TPR_non_protected': 0.9375, 'TNR_protected': 0.7435897435897436, 'TNR_non_protected': 0.7466666666666667}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.8450292397660819, 'accuracy': 0.8333333333333334, 'f1-score': 0.8333333333333331, 'fairness': 0.0030769230769230327, 'TPR_protected': 0.9615384615384616, 'TPR_non_protected': 0.9375, 'TNR_protected': 0.7435897435897436, 'TNR_non_protected': 0.7466666666666667}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.8450292397660819, 'accuracy': 0.8333333333333334, 'f1-score': 0.8333333333333331, 'fairness': -0.11052631578947367, 'TPR_protected': 0.9615384615384616, 'TPR_non_protected': 0.9375, 'TNR_protected': 0.7435897435897436, 'TNR_non_protected': 0.7466666666666667}\n"
     ]
    }
   ],
   "source": [
    "run_eval('credit-approval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 30000\n",
      "Number of attribute: 24\n",
      "Length (cleaned): 30000\n",
      "Class imbalance: \n",
      " 0    23364\n",
      "1     6636\n",
      "Name: default payment, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.6270045802411874, 'accuracy': 0.8124444444444444, 'f1-score': 0.4093771868439468, 'fairness': 0.006753040471380964}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.6270045802411874, 'accuracy': 0.8124444444444444, 'f1-score': 0.4093771868439468, 'fairness': 0.0016504364900363777, 'TPR_protected': 0.29775784753363227, 'TPR_non_protected': 0.29940828402366865, 'TNR_protected': 0.9553007254856073, 'TNR_non_protected': 0.9559089266353451}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.6270045802411874, 'accuracy': 0.8124444444444444, 'f1-score': 0.4093771868439468, 'fairness': 0.03986743148502225, 'TPR_protected': 0.29775784753363227, 'TPR_non_protected': 0.29940828402366865, 'TNR_protected': 0.9553007254856073, 'TNR_non_protected': 0.9559089266353451}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.6270045802411874, 'accuracy': 0.8124444444444444, 'f1-score': 0.4093771868439468, 'fairness': 0.0006082011497378359, 'TPR_protected': 0.29775784753363227, 'TPR_non_protected': 0.29940828402366865, 'TNR_protected': 0.9553007254856073, 'TNR_non_protected': 0.9559089266353451}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.6270045802411874, 'accuracy': 0.8124444444444444, 'f1-score': 0.4093771868439468, 'fairness': -0.752982576602867, 'TPR_protected': 0.29775784753363227, 'TPR_non_protected': 0.29940828402366865, 'TNR_protected': 0.9553007254856073, 'TNR_non_protected': 0.9559089266353451}\n"
     ]
    }
   ],
   "source": [
    "run_eval('credit-card')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 8755\n",
      "Number of attribute: 18\n",
      "Length (cleaned): 8755\n",
      "Class imbalance: \n",
      " 1    8059\n",
      "0     696\n",
      "Name: label, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.9922970743450692, 'accuracy': 0.9931480776551199, 'f1-score': 0.9962358845671268, 'fairness': 0.029941378989485457}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.9922970743450692, 'accuracy': 0.9931480776551199, 'f1-score': 0.9962358845671268, 'fairness': 0.0001387805178727497, 'TPR_protected': 0.9932750504371217, 'TPR_non_protected': 0.9934138309549945, 'TNR_protected': 0.9877300613496932, 'TNR_non_protected': 1.0}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.9922970743450692, 'accuracy': 0.9931480776551199, 'f1-score': 0.9962358845671268, 'fairness': 0.0013522650439485862, 'TPR_protected': 0.9932750504371217, 'TPR_non_protected': 0.9934138309549945, 'TNR_protected': 0.9877300613496932, 'TNR_non_protected': 1.0}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.9922970743450692, 'accuracy': 0.9931480776551199, 'f1-score': 0.9962358845671268, 'fairness': 0.012269938650306749, 'TPR_protected': 0.9932750504371217, 'TPR_non_protected': 0.9934138309549945, 'TNR_protected': 0.9877300613496932, 'TNR_non_protected': 1.0}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.9922970743450692, 'accuracy': 0.9931480776551199, 'f1-score': 0.9962358845671268, 'fairness': -inf, 'TPR_protected': 0.9932750504371217, 'TPR_non_protected': 0.9934138309549945, 'TNR_protected': 0.9877300613496932, 'TNR_non_protected': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_eval('credit-scoring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 1000\n",
      "Number of attribute: 22\n",
      "Length (cleaned): 1000\n",
      "Class imbalance: \n",
      " 1    700\n",
      "0    300\n",
      "Name: class-label, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.30333333333333334, 'f1-score': 0.0, 'fairness': 0.0}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.30333333333333334, 'f1-score': 0.0, 'fairness': 0.0, 'TPR_protected': 0.0, 'TPR_non_protected': 0.0, 'TNR_protected': 1.0, 'TNR_non_protected': 1.0}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.30333333333333334, 'f1-score': 0.0, 'fairness': 0.0, 'TPR_protected': 0.0, 'TPR_non_protected': 0.0, 'TNR_protected': 1.0, 'TNR_non_protected': 1.0}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.30333333333333334, 'f1-score': 0.0, 'fairness': 0.0, 'TPR_protected': 0.0, 'TPR_non_protected': 0.0, 'TNR_protected': 1.0, 'TNR_non_protected': 1.0}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.30333333333333334, 'f1-score': 0.0, 'fairness': nan, 'TPR_protected': 0.0, 'TPR_non_protected': 0.0, 'TNR_protected': 1.0, 'TNR_non_protected': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_eval('german-credit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 50000\n",
      "Number of attribute: 47\n",
      "Length (cleaned): 38896\n",
      "Class imbalance: \n",
      " 0    28747\n",
      "1    10149\n",
      "Name: TARGET_LABEL_BAD, dtype: int64\n",
      "Statistical parity:\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.7352815151255463, 'f1-score': 0.0, 'fairness': 0.0}\n",
      "Equal opportunity\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.7352815151255463, 'f1-score': 0.0, 'fairness': 0.0, 'TPR_protected': 0.0, 'TPR_non_protected': 0.0, 'TNR_protected': 1.0, 'TNR_non_protected': 1.0}\n",
      "Predictive parity\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.7352815151255463, 'f1-score': 0.0, 'fairness': 0.0, 'TPR_protected': 0.0, 'TPR_non_protected': 0.0, 'TNR_protected': 1.0, 'TNR_non_protected': 1.0}\n",
      "Predictive equality\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.7352815151255463, 'f1-score': 0.0, 'fairness': 0.0, 'TPR_protected': 0.0, 'TPR_non_protected': 0.0, 'TNR_protected': 1.0, 'TNR_non_protected': 1.0}\n",
      "Treatment equality\n",
      "{'balanced_accuracy': 0.5, 'accuracy': 0.7352815151255463, 'f1-score': 0.0, 'fairness': nan, 'TPR_protected': 0.0, 'TPR_non_protected': 0.0, 'TNR_protected': 1.0, 'TNR_non_protected': 1.0}\n"
     ]
    }
   ],
   "source": [
    "run_eval('PAKDD')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "07f77a1088ec27c511ada81280526a5a9813c372362ef5dc18ab18682e528864"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
